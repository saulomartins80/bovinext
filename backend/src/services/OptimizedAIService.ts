import OpenAI from 'openai';
import { AppError } from '../core/errors/AppError';
import { ChatMessage } from '../types/chat';
import { EventEmitter } from 'events';

// ===== CONFIGURA√á√ÉO OTIMIZADA =====
const openai = new OpenAI({
  apiKey: process.env.DEEPSEEK_API_KEY,
  baseURL: 'https://api.deepseek.com/v1',
  timeout: 30000, // Aumentado para 30 segundos
});

// ===== SISTEMA DE CACHE INTELIGENTE =====
class IntelligentCache {
  private cache = new Map<string, any>();
  private accessCount = new Map<string, number>();
  private lastAccess = new Map<string, number>();
  private readonly MAX_SIZE = 100;
  private readonly TTL = 30 * 60 * 1000; // 30 minutos

  set(key: string, value: any): void {
    // Limpar cache se necess√°rio
    if (this.cache.size >= this.MAX_SIZE) {
      this.evictLeastUsed();
    }

    this.cache.set(key, value);
    this.accessCount.set(key, 1);
    this.lastAccess.set(key, Date.now());
  }

  get(key: string): any {
    const value = this.cache.get(key);
    if (!value) return null;

    // Verificar TTL
    const lastAccess = this.lastAccess.get(key) || 0;
    if (Date.now() - lastAccess > this.TTL) {
      this.delete(key);
      return null;
    }

    // Atualizar estat√≠sticas
    this.accessCount.set(key, (this.accessCount.get(key) || 0) + 1);
    this.lastAccess.set(key, Date.now());
    
    return value;
  }

  private evictLeastUsed(): void {
    let leastUsedKey = '';
    let leastCount = Infinity;

    for (const [key, count] of this.accessCount) {
      if (count < leastCount) {
        leastCount = count;
        leastUsedKey = key;
      }
    }

    if (leastUsedKey) {
      this.delete(leastUsedKey);
    }
  }

  private delete(key: string): void {
    this.cache.delete(key);
    this.accessCount.delete(key);
    this.lastAccess.delete(key);
  }

  clear(): void {
    this.cache.clear();
    this.accessCount.clear();
    this.lastAccess.clear();
  }

  getStats() {
    return {
      size: this.cache.size,
      hitRate: this.calculateHitRate(),
      mostAccessed: this.getMostAccessed()
    };
  }

  private calculateHitRate(): number {
    const total = Array.from(this.accessCount.values()).reduce((a, b) => a + b, 0);
    return total > 0 ? (this.cache.size / total) * 100 : 0;
  }

  private getMostAccessed(): Array<{key: string, count: number}> {
    return Array.from(this.accessCount.entries())
      .sort(([,a], [,b]) => b - a)
      .slice(0, 5)
      .map(([key, count]) => ({ key: key.substring(0, 50), count }));
  }
}

// ===== SISTEMA DE DETEC√á√ÉO DE INTEN√á√ïES R√ÅPIDO =====
class FastIntentDetector {
  private patterns = {
    CREATE_TRANSACTION: [
      /gast[ei]|comprei|paguei|despesa|receita|transa√ß√£o/i,
      /registr[ao]|adicionar|criar.*transa√ß√£o/i,
      /valor.*r\$|\$|real|reais/i
    ],
    CREATE_GOAL: [
      /meta|objetivo|juntar|poupar|economizar/i,
      /quero.*r\$|preciso.*r\$/i,
      /plano.*financeiro|planejamento/i
    ],
    CREATE_INVESTMENT: [
      /invest[ir]|aplicar|render|cdb|tesouro|a√ß√µes/i,
      /bolsa|b3|nubank|inter|btg/i,
      /rentabilidade|juros|dividendos/i
    ],
    ANALYZE_DATA: [
      /analis[ae]|relat√≥rio|gr√°fico|dashboard/i,
      /como.*gast[oa]|onde.*gast[oa]/i,
      /resumo|balan√ßo|situa√ß√£o.*financeira/i
    ],
    MILEAGE: [
      /milhas|pontos|smiles|tudoazul|latam/i,
      /cart√£o.*cr√©dito|programa.*fidelidade/i,
      /resgat[ae]|acumular.*pontos/i
    ],
    HELP: [
      /ajuda|help|como.*usar|n√£o.*sei/i,
      /tutorial|explicar|ensinar/i,
      /o que.*posso|funcionalidades/i
    ],
    GREETING: [
      /oi|ol√°|hey|bom.*dia|boa.*tarde|boa.*noite/i,
      /tudo.*bem|como.*vai|beleza/i
    ]
  };

  detect(message: string): { intent: string; confidence: number; entities: any } {
    const lowerMessage = message.toLowerCase();
    let bestMatch = { intent: 'UNKNOWN', confidence: 0.0, entities: {} };

    for (const [intent, patterns] of Object.entries(this.patterns)) {
      let matches = 0;
      const entities: any = {};

      for (const pattern of patterns) {
        if (pattern.test(lowerMessage)) {
          matches++;
        }
      }

      // Extrair entidades espec√≠ficas
      if (intent === 'CREATE_TRANSACTION') {
        const valueMatch = message.match(/r\$\s*(\d+(?:[.,]\d{2})?)/i);
        if (valueMatch) {
          entities.valor = parseFloat(valueMatch[1].replace(',', '.'));
        }
      }

      const confidence = matches / patterns.length;
      if (confidence > bestMatch.confidence) {
        bestMatch = { intent, confidence, entities };
      }
    }

    return bestMatch;
  }
}

// ===== SISTEMA DE STREAMING INTELIGENTE =====
class StreamingResponse extends EventEmitter {
  private buffer = '';
  private isComplete = false;

  async streamResponse(prompt: string, onChunk: (chunk: string) => void): Promise<string> {
    try {
      const stream = await openai.chat.completions.create({
        model: 'deepseek-chat',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
        max_tokens: 500,
        stream: true,
      });

      let fullResponse = '';

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content) {
          fullResponse += content;
          onChunk(content);
          this.emit('chunk', content);
        }
      }

      this.isComplete = true;
      this.emit('complete', fullResponse);
      return fullResponse;
    } catch (error) {
      this.emit('error', error);
      throw error;
    }
  }
}

// ===== SISTEMA DE CONTEXTO OTIMIZADO =====
class OptimizedContext {
  private userContexts = new Map<string, any>();

  updateContext(userId: string, message: string, response: string): void {
    const existing = this.userContexts.get(userId) || {
      recentTopics: [],
      preferences: { style: 'balanced' },
      lastInteraction: Date.now(),
      messageCount: 0
    };

    existing.recentTopics.unshift(this.extractTopic(message));
    existing.recentTopics = existing.recentTopics.slice(0, 5); // Manter apenas 5 t√≥picos recentes
    existing.lastInteraction = Date.now();
    existing.messageCount++;

    this.userContexts.set(userId, existing);
  }

  getContext(userId: string): any {
    return this.userContexts.get(userId) || {
      recentTopics: [],
      preferences: { style: 'balanced' },
      lastInteraction: Date.now(),
      messageCount: 0
    };
  }

  private extractTopic(message: string): string {
    const topics = {
      'investimento': /invest|aplicar|render|cdb|tesouro/i,
      'gastos': /gast|compra|despesa|pagar/i,
      'metas': /meta|objetivo|poupar|juntar/i,
      'milhas': /milhas|pontos|cart√£o/i,
      'an√°lise': /analis|relat√≥rio|gr√°fico/i
    };

    for (const [topic, pattern] of Object.entries(topics)) {
      if (pattern.test(message)) {
        return topic;
      }
    }

    return 'geral';
  }
}

// ===== CLASSE PRINCIPAL OTIMIZADA =====
export class OptimizedAIService {
  private cache = new IntelligentCache();
  private intentDetector = new FastIntentDetector();
  private contextManager = new OptimizedContext();
  private responseCount = 0;

  // Prompts otimizados e mais diretos
  private readonly SYSTEM_PROMPTS = {
    FINN_CORE: `Voc√™ √© Finn, assistente financeiro da Finnextho. Seja direto, √∫til e amig√°vel.
    
REGRAS:
- Respostas em portugu√™s brasileiro
- M√°ximo 150 palavras por resposta
- Use emojis moderadamente
- Seja proativo em sugerir a√ß√µes
- Confirme apenas a√ß√µes importantes (>R$1000 ou exclus√µes)

A√á√ïES DISPON√çVEIS:
- Criar transa√ß√µes, metas, investimentos
- Analisar dados financeiros
- Gerenciar milhas e pontos
- Explicar funcionalidades

Responda de forma natural e conversacional.`,

    QUICK_HELP: `Responda rapidamente sobre funcionalidades da FinNEXTHO. Seja conciso e direto.`,
    
    AUTOMATION: `Analise a mensagem e determine se √© uma solicita√ß√£o de automa√ß√£o. Responda em JSON:
{
  "intent": "CREATE_TRANSACTION|CREATE_GOAL|CREATE_INVESTMENT|ANALYZE_DATA|HELP|GREETING|UNKNOWN",
  "confidence": 0.0-1.0,
  "requiresConfirmation": boolean,
  "entities": {},
  "response": "resposta amig√°vel"
}`
  };

  async generateResponse(
    userId: string,
    message: string,
    conversationHistory: ChatMessage[] = [],
    userContext?: any
  ): Promise<{
    text: string;
    intent?: string;
    confidence?: number;
    requiresConfirmation?: boolean;
    entities?: any;
    responseTime: number;
    cached?: boolean;
  }> {
    const startTime = Date.now();
    
    try {
      // 1. Verificar cache primeiro (inclui "impress√£o" do hist√≥rico recente para evitar respostas fora de contexto)
      const historyKey = (conversationHistory || [])
        .slice(-3)
        .map(m => (typeof m.content === 'string' ? m.content : ''))
        .join('|')
        .toLowerCase()
        .replace(/\s+/g, ' ')
        .substring(0, 120);
      const cacheKey = this.getCacheKey(userId, message, historyKey);
      const cached = this.cache.get(cacheKey);
      if (cached) {
        console.log(`[OptimizedAI] Cache hit for user ${userId}`);
        return {
          ...cached,
          responseTime: Date.now() - startTime,
          cached: true
        };
      }

      // 2. Detec√ß√£o r√°pida de inten√ß√£o
      const intentResult = this.intentDetector.detect(message);
      
      // 3. Atualizar contexto
      this.contextManager.updateContext(userId, message, '');

      // 4. Gerar resposta baseada na inten√ß√£o
      let response: string;
      let requiresConfirmation = false;

      if (intentResult.confidence > 0.7) {
        // Alta confian√ßa - usar automa√ß√£o
        response = await this.generateAutomatedResponse(intentResult, message, userContext);
        requiresConfirmation = this.shouldRequireConfirmation(intentResult);
      } else {
        // Baixa confian√ßa - usar resposta conversacional
        response = await this.generateConversationalResponse(message, conversationHistory, userContext);
      }

      // 5. P√≥s-processamento
      response = this.postProcessResponse(response, userContext);

      // 6. Salvar no cache
      const result = {
        text: response,
        intent: intentResult.intent,
        confidence: intentResult.confidence,
        requiresConfirmation,
        entities: intentResult.entities,
        responseTime: Date.now() - startTime
      };

      this.cache.set(cacheKey, result);
      this.responseCount++;

      return result;

    } catch (error) {
      console.error('[OptimizedAI] Error generating response:', error);
      return {
        text: 'Desculpe, tive um problema t√©cnico. Pode tentar novamente?',
        responseTime: Date.now() - startTime,
        confidence: 0.0
      };
    }
  }

  async streamResponse(
    userId: string,
    message: string,
    onChunk: (chunk: string) => void
  ): Promise<string> {
    const streamer = new StreamingResponse();
    const prompt = this.buildStreamPrompt(message, userId);
    
    return streamer.streamResponse(prompt, onChunk);
  }

  private async generateAutomatedResponse(
    intentResult: any,
    message: string,
    userContext?: any
  ): Promise<string> {
    const responses = {
      CREATE_TRANSACTION: `Perfeito! Vou ajudar voc√™ a registrar essa transa√ß√£o. ${
        intentResult.entities.valor ? 
        `Vi que o valor √© R$ ${intentResult.entities.valor}. ` : 
        'Qual foi o valor? '
      }Preciso s√≥ de mais alguns detalhes.`,
      
      CREATE_GOAL: `√ìtima ideia criar uma meta! Metas s√£o fundamentais para organizar as finan√ßas. Qual o valor que voc√™ quer juntar e para quando?`,
      
      CREATE_INVESTMENT: `Investir √© sempre uma boa! üìà Vou te ajudar a registrar esse investimento. Qual foi o valor e onde voc√™ aplicou?`,
      
      ANALYZE_DATA: `Vou analisar seus dados financeiros! ${
        userContext?.totalTransacoes > 0 ? 
        'Com base no seu hist√≥rico, posso gerar insights interessantes.' :
        'Assim que voc√™ tiver algumas transa√ß√µes, posso fazer an√°lises detalhadas.'
      }`,
      
      MILEAGE: `Milhas e pontos s√£o √≥timos para economizar! ‚úàÔ∏è Posso te ajudar a gerenciar seus programas de fidelidade. O que voc√™ quer fazer?`,
      
      HELP: `Estou aqui para ajudar! ü§ù Posso te ajudar com transa√ß√µes, investimentos, metas, an√°lises e muito mais. O que voc√™ gostaria de saber?`,
      
      GREETING: this.getPersonalizedGreeting(userContext)
    };

    return responses[intentResult.intent as keyof typeof responses] || 
           'Como posso te ajudar hoje?';
  }

  private async generateConversationalResponse(
    message: string,
    conversationHistory: ChatMessage[],
    userContext?: any
  ): Promise<string> {
    const context = this.buildContextPrompt(conversationHistory, userContext);
    const prompt = `${this.SYSTEM_PROMPTS.FINN_CORE}\n\nContexto: ${context}\n\nUsu√°rio: ${message}\n\nFinn:`;

    const completion = await openai.chat.completions.create({
      model: 'deepseek-chat',
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.7,
      max_tokens: 200,
    });

    return completion.choices[0]?.message?.content || 'Como posso te ajudar?';
  }

  private shouldRequireConfirmation(intentResult: any): boolean {
    // Confirmar apenas para a√ß√µes importantes
    if (intentResult.entities.valor && intentResult.entities.valor > 1000) {
      return true;
    }
    
    if (intentResult.intent === 'CREATE_INVESTMENT' && intentResult.entities.valor > 500) {
      return true;
    }

    return false;
  }

  private getPersonalizedGreeting(userContext?: any): string {
    const greetings = [
      'Oi! Como posso te ajudar hoje? üòä',
      'Ol√°! Pronto para cuidar das suas finan√ßas? üí∞',
      'Hey! O que vamos fazer hoje? üöÄ',
      'Oi! Como est√£o suas finan√ßas? üìä'
    ];

    if (userContext?.messageCount > 10) {
      greetings.push('E a√≠! Bom te ver de novo! üëã');
    }

    return greetings[Math.floor(Math.random() * greetings.length)];
  }

  private buildContextPrompt(conversationHistory: ChatMessage[], userContext?: any): string {
    const recentMessages = conversationHistory.slice(-3);
    const context = recentMessages.map(msg => 
      `${msg.sender}: ${typeof msg.content === 'string' ? msg.content : '[Conte√∫do complexo]'}`
    ).join('\n');

    const userInfo = userContext ? 
      `Usu√°rio tem ${userContext.totalTransacoes || 0} transa√ß√µes, ${userContext.totalMetas || 0} metas.` : 
      '';

    return `${context}\n${userInfo}`;
  }

  private buildStreamPrompt(message: string, userId: string): string {
    const context = this.contextManager.getContext(userId);
    return `${this.SYSTEM_PROMPTS.FINN_CORE}\n\nT√≥picos recentes: ${context.recentTopics.join(', ')}\n\nUsu√°rio: ${message}\n\nFinn:`;
  }

  private postProcessResponse(response: string, userContext?: any): string {
    // Adicionar elementos premium se aplic√°vel
    if (userContext?.subscriptionPlan === 'top' || userContext?.subscriptionPlan === 'enterprise') {
      if (Math.random() < 0.3) { // 30% das vezes
        response += '\n\nüíé Como cliente premium, voc√™ tem acesso a an√°lises exclusivas!';
      }
    }

    return response.trim();
  }

  private getCacheKey(userId: string, message: string, historyKey: string = ''): string {
    const base = `${userId}_${message.substring(0, 50).toLowerCase().replace(/\s+/g, '_')}`;
    if (!historyKey) return base;
    const hist = historyKey.substring(0, 80).replace(/\s+/g, '_');
    return `${base}__h:${hist}`;
  }

  // M√©todos de utilidade
  getCacheStats() {
    return {
      ...this.cache.getStats(),
      totalResponses: this.responseCount
    };
  }

  clearCache() {
    this.cache.clear();
  }

  // M√©todo para compatibilidade com o sistema existente
  async generateContextualResponse(
    systemPrompt: string,
    userMessage: string,
    conversationHistory: ChatMessage[],
    userContext?: any
  ) {
    const userId = userContext?.userId || 'anonymous';
    const result = await this.generateResponse(userId, userMessage, conversationHistory, userContext);
    
    return {
      text: result.text,
      analysisData: {
        responseTime: result.responseTime,
        engine: 'optimized',
        confidence: result.confidence || 0.8,
        cached: result.cached || false
      }
    };
  }
}

export default OptimizedAIService;
